{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "1. Try different models and see which one fits the best the given data\n",
    "1. Get a higher score than the given one in the current baseline example\n",
    "1. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#from ml.visualization import plot_confusion_matrix, plot_learning_curve\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(1234) # Para mayor determinismo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the given labels\n",
    "breed = pd.read_csv('../data/breed_labels.csv')\n",
    "color = pd.read_csv('../data/color_labels.csv')\n",
    "state = pd.read_csv('../data/state_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create a function to transform the datasets. This is done by means of a function so that the transformations are the same for the training and testing datasets... We replace the encodings just to make it easy to \"visualize\" the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    def transform_columns(df):\n",
    "        df = df.drop([\"Description\"], axis=1)\n",
    "        df.Type = df.Type.replace({1: 'Dog', 2: 'Cat'})\n",
    "        df.Gender = df.Gender.replace({1:'Male', 2:'Female', 3:'Mixed'})\n",
    "        df.MaturitySize = df.MaturitySize.replace({1:'S', 2:'M', 3:'L', 4:'XL', 0:'N/A'})\n",
    "        df.FurLength = df.FurLength.replace({1:'S', 2:'M', 3:'L', 0:'N/A'})\n",
    "        df.Vaccinated = df.Vaccinated.replace({1:'T', 2:'N', 3:'N/A'})\n",
    "        df.Dewormed = df.Dewormed.replace({1:'T', 2:'F', 3:'N/A'})\n",
    "        df.Sterilized = df.Sterilized.replace({1:'T', 2:'F', 3:'N/A'})\n",
    "        df.Health = df.Health.replace({1:'Healthy', 2: 'MinorInjury', 3:'SeriousInjury', 0: 'N/A'})\n",
    "        df.Color1 = df.Color1.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Color2 = df.Color2.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Color3 = df.Color3.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Breed1 = df.Breed1.replace(dict(list(zip(breed.BreedID, breed.BreedName)) + [(0, \"N/A\")]))\n",
    "        df.Breed2 = df.Breed2.replace(dict(list(zip(breed.BreedID, breed.BreedName)) + [(0, \"N/A\")]))\n",
    "        return df\n",
    "    \n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train = transform_columns(df_train)\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test = transform_columns(df_test)\n",
    "    \n",
    "    df = pd.concat([df_train, df_test], sort=True)\n",
    "\n",
    "    # set dummy variables for everything\n",
    "    # except from Age, Quantity, Fee\n",
    "    df = pd.get_dummies(df)\n",
    "    # get train and test back\n",
    "    n = len(df_train)\n",
    "    df_train = df.iloc[:n]\n",
    "    df_test = df.iloc[n:]\n",
    "    \n",
    "    y = df_train['AdoptionSpeed']\n",
    "    X = df_train.drop('AdoptionSpeed', axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop('AdoptionSpeed', axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor conjunto de par치metros:\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'best', 'n_estimators': 1}\n",
      "\n",
      "Mejor Estimador:\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
      "                                                         criterion='entropy',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features='auto',\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=11,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=1, random_state=None)\n",
      "\n",
      "Mejor Accuracy:\n",
      "0.2997164844066424\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1120x320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "plt.figure(figsize=(14, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "results = []\n",
    "\n",
    "\n",
    "#HIPERPARAMETROS\n",
    "\n",
    "exploring_params = {'base_estimator__criterion' : ['gini', 'entropy'],\n",
    "              'base_estimator__splitter' :   ['best', 'random'],\n",
    "              'n_estimators': [1, 2]\n",
    "             }\n",
    "DTC = DecisionTreeClassifier(random_state = 11, max_features = 'auto', class_weight ='balanced',max_depth = None)\n",
    "\n",
    "ABC = AdaBoostClassifier(base_estimator = DTC)\n",
    "\n",
    "#m = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "model = GridSearchCV(ABC, exploring_params, cv=5, scoring='accuracy')\n",
    "   \n",
    "#entrenar los datos de entrenamiento eliminando los PID para entrenar\n",
    "model.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "\n",
    "  \n",
    "print(\"Mejor conjunto de par치metros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "    \n",
    "print(\"Mejor Estimador:\")\n",
    "print(model.best_estimator_, end=\"\\n\\n\")\n",
    "    \n",
    "print(\"Mejor Accuracy:\")\n",
    "print(model.best_score_, end=\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({'clf': model.best_estimator_, 'best_acc': model.best_score_}) #sacar el ignore index para results como lista\n",
    "    results = pd.DataFrame(results)\n",
    "    \n",
    "    print('The best classifier so far is: ')\n",
    "    print(results.loc[results['best_acc'].idxmax()]['clf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediccion\n",
    "\n",
    "print(\"Reporte de clasificaci칩n para el mejor clasificador (sobre conjunto de evaluaci칩n):\", end=\"\\n\\n\")\n",
    "yy = results.model.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission.to_csv(\"../data/submission-SGDClassifier.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
