{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rq0dgjrJjOtm"
   },
   "source": [
    "# Procesamiento de datos usando Tensorflow\n",
    "\n",
    "Cuando trabajamos con Tensorflow, existen una gran variedad de formas en las que podemos alimentar los datos a nuestra red neuronal. Esto también tiene que ver con el tipo de datos y los pasos de pre-procesamiento que sean necesarios.\n",
    "\n",
    "En la notebook 1 se utilizó un conjunto de datos de imágenes, esencialmente con variables numéricas. En esta notebook trabajemos con datos categóricos y profundizaremos en cómo trasformar los ejemplos dentro del pipeline de clasificación.\n",
    "\n",
    "Ante un problema de clasificación, lo primero que debemos hacer es **inspeccionar los datos y construir un prototipo de modelo**. La forma más fácil de hacerlo es con notebooks. Sin embargo, a la hora de llevar a cabo experimentos con redes neuronales, un entorno interactivo puede no ser la mejor opción. En primer lugar, explorar los hiperparámetros de una arquitectura neuronal puede llevar varias horas e incluso días, perdiendo todas las ventajas del entorno interactivo. En segundo lugar, no podemos encolar ejecuciones de notebooks para reservar recursos como las GPUs.\n",
    "\n",
    "Por ello, primero realizaremos una exploración inicial de los datos en esta notebook. Una vez que decidamos qué tipo de modelo implementar, pasaremos el modelo a un script de python que cargue los datos, construya el modelo, lo entrene, y finalmente guarde las métricas relevantes.\n",
    "\n",
    "En esta notebook, veremos varios conceptos avanzados de entrenamiento de redes:\n",
    "\n",
    "  * Uso de `tf.data.Dataset` para optimizar la ingesta de datos. \n",
    "  * Uso de capas `tf.layers.Embedding`.\n",
    "  * Combinación de distintos tipos de features en un mismo modelo con múltiples inputs.\n",
    "  * MLFlow para registro de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mH6SnHmAHyGF",
    "outputId": "6b2f0c84-2459-4f82-ad81-8bb09f21b273"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16sGzSSpjOty"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZEld4Ku5jOuE"
   },
   "source": [
    "## Cargando los datos\n",
    "\n",
    "Una vez más, estaremos trabajando con el conjunto de datos `petfinder`. Deben descargarlo siguiendo las instrucciones en la [notebook 0](./0_set_up.ipynb), descomprimirlo y luego ajustar la dirección en esta notebook según corresponda. \n",
    "\n",
    "Algunas de las preguntas que respondemos durante esta etapa son:\n",
    "\n",
    " * ¿Qué tipo de tarea tengo que resolver? ¿Clasificación o regresión?\n",
    " * ¿Qué distribución tienen mis etiquetas?\n",
    " * ¿Qué tipo de datos tengo disponible para la clasificación? ¿Cuáles son útiles?\n",
    " * Dadas las características disponibles y el problema que quiero resolver, ¿qué tipo de clasificador o arquitectura conviene utilizar? ¿De qué manera se están representando las causas latentes del problema en el modelo elegido?\n",
    " * Dadas las características disponibles y el modelo elegido, ¿de qué forma representaremos cada una de dichas características?\n",
    " \n",
    "En esta clase utilizaremos redes neuronales como modelos porque es el objetivo de la materia, pero sigue siendo importante qué aspectos podremos capturar con este tipo de modelo, especialmente para tener intuiciones sobre qué hiperparámetros explorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZuUc06NjOuH"
   },
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = './petfinder-dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSwpslCejOuT"
   },
   "outputs": [],
   "source": [
    "# Take a sample of data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset, dev_dataset = train_test_split(\n",
    "    pandas.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv')), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "-090Tt4zjOup",
    "outputId": "e8f9660a-7381-48db-9219-980ce1d0f192"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>Description</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>'Brownie' was found on / trailing after a jogg...</td>\n",
       "      <td>3</td>\n",
       "      <td>5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>307</td>\n",
       "      <td>179</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41336</td>\n",
       "      <td>A friend who works in pet shop informed that t...</td>\n",
       "      <td>2</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1613</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>5-6 week old kitten for adoption. Some evil pe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4329</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>Mother cat visits my home and has delivered th...</td>\n",
       "      <td>2</td>\n",
       "      <td>6133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>Handsom boy looking for a forever home. Intere...</td>\n",
       "      <td>2</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "4002     1    3     307       0       2       1       2       0             2   \n",
       "334      1   24     307     179       2       1       0       0             1   \n",
       "1613     2    2     266       0       1       6       7       0             2   \n",
       "4329     2    1     266       0       1       1       6       7             2   \n",
       "792      1    4      76     307       1       1       7       0             2   \n",
       "\n",
       "      FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  \\\n",
       "4002          2           2         1           2       1         1    0   \n",
       "334           1           3         1           3       2         1    0   \n",
       "1613          1           2         2           2       1         1    0   \n",
       "4329          1           2         2           2       1         2    0   \n",
       "792           1           1         1           2       1         1    0   \n",
       "\n",
       "      State                                        Description  AdoptionSpeed  \\\n",
       "4002  41326  'Brownie' was found on / trailing after a jogg...              3   \n",
       "334   41336  A friend who works in pet shop informed that t...              2   \n",
       "1613  41326  5-6 week old kitten for adoption. Some evil pe...              2   \n",
       "4329  41326  Mother cat visits my home and has delivered th...              2   \n",
       "792   41326  Handsom boy looking for a forever home. Intere...              2   \n",
       "\n",
       "       PID  \n",
       "4002  5659  \n",
       "334    483  \n",
       "1613  2299  \n",
       "4329  6133  \n",
       "792   1127  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jc-o9wFLjOu5"
   },
   "source": [
    "### Tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "03yY3H9SjOu9",
    "outputId": "4277301a-0491-4e92-c821-e3717bc1ca95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type              int64\n",
       "Age               int64\n",
       "Breed1            int64\n",
       "Breed2            int64\n",
       "Gender            int64\n",
       "Color1            int64\n",
       "Color2            int64\n",
       "Color3            int64\n",
       "MaturitySize      int64\n",
       "FurLength         int64\n",
       "Vaccinated        int64\n",
       "Dewormed          int64\n",
       "Sterilized        int64\n",
       "Health            int64\n",
       "Quantity          int64\n",
       "Fee               int64\n",
       "State             int64\n",
       "Description      object\n",
       "AdoptionSpeed     int64\n",
       "PID               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "918GuwcljOvK"
   },
   "outputs": [],
   "source": [
    "target_col = 'AdoptionSpeed'\n",
    "nlabels = dataset[target_col].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_PsLZ7cjOvY"
   },
   "source": [
    "### Distribución de las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "NqNloodzjOvf",
    "outputId": "a88ada65-d3a2-4bf4-ca93-481b0b42f691"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARe0lEQVR4nO3de6xlZX3G8e/DxVpvYQgjRYZ0pnSqGWtFnSBe0lC0OFAraKhKqo6UZJoGjba2Db2kWIxJr9aqFEPLCFiFYJBKLYFOkWhsQRgsctUydbBA0RmgKtbUBvrrH/s9zhbOmXcPnn3WnjnfT7Kz13rXu9f6sQLnYd3elapCkqTd2W/oAiRJs8+wkCR1GRaSpC7DQpLUZVhIkroOGLqAadiwYUNdddVVQ5chSXubLLRgnzyyeOCBB4YuQZL2KftkWEiSFpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXPjnchyQthjVr7h66hKnYvn31Hv/GIwtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLm+dlfAWSanHIwtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdU0tLJIckeTaJHckuT3JO1r7wUm2JLmrfa9o7UnygSTbktyS5IVj69rY+t+VZOO0apYkzW+aRxaPAO+qqnXAMcAZSdYBZwLXVNVa4Jo2D3ACsLZ9NgHnwihcgLOAFwNHA2fNBYwkaWlMLSyq6v6q+mKbfhi4EzgcOAm4sHW7EDi5TZ8EXFQj1wMHJTkMeBWwpaoeqqr/ArYAG6ZVtyTp8ZbkmkWS1cALgC8Ah1bV/W3R14FD2/ThwD1jP7u3tS3U/thtbEqyNcnWnTt3Lmr9krTcTT0skjwNuAx4Z1V9e3xZVRVQi7GdqjqvqtZX1fqVK1cuxiolSc1UwyLJgYyC4mNV9cnW/I12eon2vaO13wccMfbzVa1toXZJ0hKZ5t1QAc4H7qyq940tugKYu6NpI/Cpsfa3tLuijgG+1U5XXQ0cn2RFu7B9fGuTJC2RA6a47pcBbwZuTXJza/td4I+AS5OcDnwNeH1bdiVwIrAN+C5wGkBVPZTkPcCNrd/ZVfXQFOuWJD3G1MKiqj4PZIHFr5infwFnLLCuzcDmxatOkrQnfIJbktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpK5pPsEtaS+0Zs3dQ5cwFdu3rx66hL2aRxaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdflQ3jLmw1eSJuWRhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKlramGRZHOSHUluG2t7d5L7ktzcPieOLfudJNuSfCXJq8baN7S2bUnOnFa9kqSFTfPI4gJgwzztf1FVR7XPlQBJ1gFvBJ7bfvNXSfZPsj9wDnACsA44tfWVJC2hqb2Du6o+l2T1hN1PAi6pqu8B25NsA45uy7ZV1VcBklzS+t6xyOVKknZjiGsWb0tySztNtaK1HQ7cM9bn3ta2UPvjJNmUZGuSrTt37pxG3ZK0bC11WJwLHAkcBdwP/Plirbiqzquq9VW1fuXKlYu1WkkSUzwNNZ+q+sbcdJK/Bj7dZu8Djhjruqq1sZt2SdISWdIjiySHjc2+Fpi7U+oK4I1JfiTJGmAtcANwI7A2yZokT2J0EfyKpaxZkjTFI4skFwPHAockuRc4Czg2yVFAAXcDvwpQVbcnuZTRhetHgDOq6tG2nrcBVwP7A5ur6vZp1SxJmt8074Y6dZ7m83fT/73Ae+dpvxK4chFLkyTtIZ/gliR1GRaSpC7DQpLUZVhIkroMC0lS10RhkeSaSdokSfum3d46m+TJwFMYPSuxAkhb9AwWGKNJkrTv6T1n8avAO4FnATexKyy+DXxoinVJkmbIbsOiqv4S+Mskb6+qDy5RTZKkGTPRE9xV9cEkLwVWj/+mqi6aUl2SpBkyUVgk+SijocVvBh5tzQUYFpK0DEw6NtR6YF1V1TSLkSTNpkmfs7gN+LFpFiJJml2THlkcAtyR5Abge3ONVfWaqVQlSZopk4bFu6dZhCRptk16N9Rnp12IJGl2TXo31MOM7n4CeBJwIPDfVfWMaRUmSZodkx5ZPH1uOkmAk4BjplWUJGm27PGoszXyd8CrplCPJGkGTXoa6nVjs/sxeu7if6ZSkSRp5kx6N9Qvjk0/AtzN6FSUJGkZmPSaxWnTLkSSNLsmffnRqiSXJ9nRPpclWTXt4iRJs2HSC9wfAa5g9F6LZwF/39okScvApGGxsqo+UlWPtM8FwMop1iVJmiGThsWDSd6UZP/2eRPw4DQLkyTNjknD4leA1wNfB+4HTgHeOqWaJEkzZtJbZ88GNlbVfwEkORj4M0YhIknax016ZPEzc0EBUFUPAS+YTkmSpFkzaVjsl2TF3Ew7spj0qESStJeb9A/+nwPXJflEm/8l4L3TKUmSNGsmfYL7oiRbgeNa0+uq6o7plSVJmiUTn0pq4WBASNIytMdDlEuSlp+phUWSzW0cqdvG2g5OsiXJXe17RWtPkg8k2ZbkliQvHPvNxtb/riQbp1WvJGlh0zyyuADY8Ji2M4FrqmotcE2bBzgBWNs+m4Bz4ft3XZ0FvBg4Gjhr/K4sSdLSmFpYVNXngIce03wScGGbvhA4eaz9ovYWvuuBg5IcxuhtfFuq6qH2nMcWHh9AkqQpW+prFodW1f1t+uvAoW36cOCesX73traF2h8nyaYkW5Ns3blz5+JWLUnL3GAXuKuqgFrE9Z1XVeurav3KlQ6IK0mLaanD4hvt9BLte0drvw84Yqzfqta2ULskaQktdVhcAczd0bQR+NRY+1vaXVHHAN9qp6uuBo5PsqJd2D6+tUmSltDUxndKcjFwLHBIknsZ3dX0R8ClSU4HvsZo2HOAK4ETgW3Ad4HTYDRgYZL3ADe2fme3QQwlSUtoamFRVacusOgV8/Qt4IwF1rMZ2LyIpUmS9pBPcEuSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoaJCyS3J3k1iQ3J9na2g5OsiXJXe17RWtPkg8k2ZbkliQvHKJmSVrOhjyy+LmqOqqq1rf5M4FrqmotcE2bBzgBWNs+m4Bzl7xSSVrmZuk01EnAhW36QuDksfaLauR64KAkhw1RoCQtV0OFRQH/mOSmJJta26FVdX+b/jpwaJs+HLhn7Lf3trYfkGRTkq1Jtu7cuXNadUvSsnTAQNt9eVXdl+SZwJYkXx5fWFWVpPZkhVV1HnAewPr16/fot5Kk3RvkyKKq7mvfO4DLgaOBb8ydXmrfO1r3+4Ajxn6+qrVJkpbIkodFkqcmefrcNHA8cBtwBbCxddsIfKpNXwG8pd0VdQzwrbHTVZKkJTDEaahDgcuTzG3/41V1VZIbgUuTnA58DXh9638lcCKwDfgucNrSlyxJy9uSh0VVfRV4/jztDwKvmKe9gDOWoDRJ0gJm6dZZSdKMMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXUO8g3tQa9bcPXQJU7F9++qhS5C0D/PIQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkrr0mLJJsSPKVJNuSnDl0PZK0nOwVYZFkf+Ac4ARgHXBqknXDViVJy8deERbA0cC2qvpqVf0vcAlw0sA1SdKysbe8g/tw4J6x+XuBF493SLIJ2NRmv5PkK0tU2+4cAjywFBtKlmIrPxT3xS7ui13cF7vMwr64qqo2zLdgbwmLrqo6Dzhv6DrGJdlaVeuHrmMWuC92cV/s4r7YZdb3xd5yGuo+4Iix+VWtTZK0BPaWsLgRWJtkTZInAW8Erhi4JklaNvaK01BV9UiStwFXA/sDm6vq9oHLmsRMnRYbmPtiF/fFLu6LXWZ6X6Sqhq5BkjTj9pbTUJKkARkWkqQuw2IKHJpklySbk+xIctvQtQwpyRFJrk1yR5Lbk7xj6JqGkuTJSW5I8qW2L/5w6JqGlmT/JP+a5NND17IQw2KROTTJ41wAzPuQzzLzCPCuqloHHAOcsYz/vfgecFxVPR84CtiQ5JiBaxraO4A7hy5idwyLxefQJGOq6nPAQ0PXMbSqur+qvtimH2b0h+HwYasaRo18p80e2D7L9k6bJKuAXwD+ZuhadsewWHzzDU2yLP8oaH5JVgMvAL4wbCXDaaddbgZ2AFuqatnuC+D9wG8D/zd0IbtjWEhLKMnTgMuAd1bVt4euZyhV9WhVHcVoNIajk/z00DUNIcmrgR1VddPQtfQYFovPoUk0ryQHMgqKj1XVJ4euZxZU1TeBa1m+17VeBrwmyd2MTlkfl+Rvhy1pfobF4nNoEj1OkgDnA3dW1fuGrmdISVYmOahN/yjw88CXh61qGFX1O1W1qqpWM/pb8ZmqetPAZc3LsFhkVfUIMDc0yZ3ApXvJ0CRTkeRi4Drg2UnuTXL60DUN5GXAmxn9n+PN7XPi0EUN5DDg2iS3MPqfqy1VNbO3jGrE4T4kSV0eWUiSugwLSVKXYSFJ6jIsJEldhoUkqcuw0D4vyclJKslzFlh+QZJTfoh1rxubPzvJK5/gug5N8uk2GusdSa58IuvZg+2tXu6jAWtyhoWWg1OBz7fvxXYyo9GFAaiqP6iqf3qC6zqb0TMHz2+j0y7r4e01WwwL7dPaWEwvB05n9IQsGflQe+fIPwHPHOv/ivZegVvbuzh+pLXfneRPWvsNSX4yyUuB1wB/2h6yO3L8KKWzrj9M8sW2bO6I5zBGA08CUFW3tP7HJvlckn9oNX84yX5t2fFJrmvr+kT75yXJi5J8NslNSa5OcthY+5eSfAk4Y2o7Xvscw0L7upOAq6rq34AHk7wIeC3wbEZHBG8BXgqjl/Iwev/GG6rqecABwK+Nretbrf1DwPur6l8YDeXyW1V1VFX9+1zHCdb1QFW9EDgX+M3Wdg5wfntJ0u8ledZY/6OBt7eajwRel+QQ4PeBV7Z1bQV+o41B9UHglKp6EbAZeG9bz0eAt7d3SUgTMyy0rzuV0QBttO9TgZ8FLm4jn/4n8Jm2/NnA9hYsABe2vnMuHvt+SWe7vXXNDSR4E7AaoKquBn4C+GvgOcC/JlnZ+t3Q3pHyaNv+yxm9RGkd8M9tuO+NwI+3bf80sKW1/z6wqo3HdFB7xwjARzv/DNL3HTB0AdK0JDkYOA54XpIC9mf0kp3Ln+Aqa4HpJ+J77ftRxv47rKqHgI8DH2+v2PxZ4MF5tldAGF3j+IFrMUmeB9xeVS95TPtBP2TNWsY8stC+7BTgo1X141W1uqqOALYz+uP7hvYCnsOAn2v9vwKsTvKTbf7NwGfH1veGse/r2vTDwNPn2XZvXY+T5LgkT2nTT2d0uuk/2uKj20jG+7Xtfx64HnjZ3DaSPDXJT7Vtr0zyktZ+YJLntuHAv5nk5W2dv7y7eqRxhoX2Zafy+KOIyxhdSL4LuAO4iPaHv6r+BzgN+ESSWxm9uezDY79d0UZKfQfw663tEuC32oXsI+c6TrCu+bwI2Nq2cR3wN1V1Y1t2I6NrJXcyCrzLq2on8Fbg4rHfPKe9zvcU4I/bheybaddlWk3ntNNT6dQjfZ+jzkoTyOjlNOur6oEBtn0s8JtV9eql3rY0xyMLSVKXRxaSpC6PLCRJXYaFJKnLsJAkdRkWkqQuw0KS1PX/W/iI52yI54IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.countplot(dataset.AdoptionSpeed, color='blue')\n",
    "seaborn.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTVn6HWxjOvw"
   },
   "source": [
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
    "\n",
    "Why not to use feature_columns https://github.com/tensorflow/tensorflow/issues/27895\n",
    "\n",
    "feature_columns doc 2.0 https://www.tensorflow.org/api_docs/python/tf/feature_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIxSFC7gjOv0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWtEDHVXjOv-"
   },
   "source": [
    "## Creando las representaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXKH3T2ojOwB"
   },
   "source": [
    "Tenemos una serie de variables categóricas y ordinales que pueden ser útiles para predecir la velocidad de adopción. Para cada una de ellas, tenemos que pensar cuál es la mejor forma de pasarla como input a la red. Analizaremos algunas de ellas:\n",
    "\n",
    "  * `Age` es una variable numérica discreta, podemos representarla con una única neurona con el valor original. Es muy importante normalizar este tipo de variables.\n",
    "  * `Gender` es una variable categórica. Como la variable tiene pocos valores, utilizaremos un *one-hot encoding* como representación.\n",
    "  * `Breed1` es una variable categórica que puede tomar muchos valores. Podemos utilizar *one-hot encoding*, lo cual resultará en vectores esparsos de dimensión cercana a 300. Alternativamente, podemos utilizar una capa de embedding para representar sus valores con un vector denso de baja dimesionalidad. Pregunta: ¿qué información podrá capturar este embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kK_QWliujOwG"
   },
   "source": [
    "Una vez que definimos cómo vamos a representar cada una de las columnas, las pre-procesamos para formar un numpy array. En este caso, procesaremos el dataset completo porque estamos seguros de que entrará en memoria. En otros casos, puede ser necesario un pre-procesamiento por batches, o incluso utilizar las funciones de Tensorflow incluidas en el módulo `feature_column`.\n",
    "\n",
    "NOTA: para este ejercicio, intentamos utilizar `feature_column` pero causaba que la loss diverga. La documentación no ha sido totalmente actualizada a Tensorflow 2.0, y puede ser que nos encontremos ante un error de cambio de versiones. Pueden encontrar más ejemplos en [este link](https://www.tensorflow.org/tutorials/structured_data/feature_columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "yimWjdQAKARc",
    "outputId": "f537e224-b61c-4b75-a3c2-3b4a2de3c629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: [1 2]\n",
      "Color2: [2 0 7 6 4 5 3]\n",
      "Color3: [0 7 4 6 3 5]\n",
      "MaturitySize: [2 1 3 4]\n",
      "FurLength: [2 1 3]\n",
      "Vaccinated: [2 3 1]\n",
      "Dewormed: [1 2 3]\n",
      "Health: [1 2 3]\n",
      "Quantity: [ 1  2  5  4  6  3  7  9  8 17 10 20 16 15 11 14 13 12 18]\n",
      "State: [41326 41336 41401 41332 41327 41330 41325 41335 41324 41361 41367 41342\n",
      " 41345 41415]\n",
      "Sterilized: [2 3 1]\n",
      "Breed2: [  0 179 307 266 292 264 254 265 295 155 109 141 218 205 252  20 103 249\n",
      " 213  26 245 150  78 299 152 195 128 283 306 285 251 117 250 102 276 247\n",
      "  76  83 270 268 188  98 202 169 271 243 248 294 227 189 305  60  75  18\n",
      " 119  49 288 147 278  72 246 207 303  69  10 300 206 146  70  39 187 274\n",
      "  58 192 304 241 239 129 173 272 104  21 167 296 260 212 267 200 122 282\n",
      " 201  44 262 115 242  40  65  24 178 159 256   5  19 302 257  96  16]\n",
      "Age: [  3  24   2   1   4  12   8  11  36   6  60   5  48  20  25 120 144  17\n",
      "  56  72  18  30  15   7  96   9  84  10  14  13  42   0  27  28  21  16\n",
      "  22  26  46  32  57  50  33  77 102  38  52  31  29  23  61  53  47  87\n",
      " 108 132  78  41  39  76  54  55  19 238  51  37  49  95 135  63  65 180\n",
      "  86  34  45  44  43  88  64 168  80  62 147 100  67 255  68  81  82 156\n",
      " 212 112  35  66 122]\n",
      "Fee: [   0  150   50  200  500  300   10   15    1  390   30  400  100  250\n",
      "   70   99   20   80  120   59    5  480  700  350   60   35   25  380\n",
      "  110   38   90  600  160  180   45  750    9  235  650   40  170    8\n",
      "  280   14  800  125  450  270  190  599  385  220  155  688  135  550\n",
      " 3000   65  299   72  320  188  499]\n"
     ]
    }
   ],
   "source": [
    "print('Type: {}'.format(dataset.Type.unique())) \n",
    "print('Color2: {}'.format(dataset.Color2.unique())) \n",
    "print('Color3: {}'.format(dataset.Color3.unique())) \n",
    "print('MaturitySize: {}'.format(dataset.MaturitySize.unique())) \n",
    "print('FurLength: {}'.format(dataset.FurLength.unique())) \n",
    "print('Vaccinated: {}'.format(dataset.Vaccinated.unique())) \n",
    "print('Dewormed: {}'.format(dataset.Dewormed.unique())) \n",
    "print('Health: {}'.format(dataset.Health.unique())) \n",
    "print('Quantity: {}'.format(dataset.Quantity.unique())) \n",
    "print('State: {}'.format(dataset.State.unique())) \n",
    "print('Sterilized: {}'.format(dataset.Sterilized.unique())) \n",
    "print('Breed2: {}'.format(dataset.Breed2.unique())) \n",
    "\n",
    "\n",
    "print('Age: {}'.format(dataset.Age.unique())) \n",
    "print('Fee: {}'.format(dataset.Fee.unique())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYt4C_ubjOwL"
   },
   "outputs": [],
   "source": [
    "# It's important to always use the same one-hot length\n",
    "one_hot_columns = {\n",
    "    one_hot_col: dataset[one_hot_col].max()\n",
    "    for one_hot_col in ['Gender', 'Color1','Color2','Color3','MaturitySize','FurLength','Vaccinated','Dewormed','Health','Type','Sterilized']\n",
    "}\n",
    "embedded_columns = {\n",
    "    embedded_col: dataset[embedded_col].max() + 1\n",
    "    for embedded_col in ['Breed1','Breed2']\n",
    "}\n",
    "numeric_columns = ['Age', 'Fee','Quantity','State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-XRlvzCjOwU"
   },
   "outputs": [],
   "source": [
    "def process_features(df):\n",
    "    direct_features = []\n",
    "\n",
    "    # Create one hot encodings\n",
    "    for one_hot_col, max_value in one_hot_columns.items():\n",
    "        direct_features.append(tf.keras.utils.to_categorical(df[one_hot_col] - 1, max_value))\n",
    "\n",
    "    # Create and append numeric columns\n",
    "    # Don't forget to normalize!\n",
    "    direct_features.append(tf.keras.utils.normalize(df[numeric_columns],1))\n",
    "        \n",
    "    \n",
    "    # Concatenate all features that don't need further embedding into a single matrix.\n",
    "    features = {'direct_features': numpy.hstack(direct_features)}\n",
    "\n",
    "    # Create embedding columns - nothing to do here. We will use the zero embedding for OOV\n",
    "    for embedded_col in embedded_columns.keys():\n",
    "        features[embedded_col] = df[embedded_col].values\n",
    "\n",
    "    # Convert labels to one-hot encodings\n",
    "    targets = tf.keras.utils.to_categorical(df[target_col], nlabels)\n",
    "    \n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2sSux-NjOwc"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = process_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "HRgHfOYojOwm",
    "outputId": "4f25b5e7-dae2-48e4-9c23-8301ec7e0599"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'direct_features': array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 2.41978415e-05, 9.99999997e-01],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 2.41919835e-05, 9.99999831e-01],\n",
       "        [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 2.41978415e-05, 9.99999999e-01],\n",
       "        ...,\n",
       "        [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 2.41978415e-05, 9.99999999e-01],\n",
       "        [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         5.31380602e-03, 2.41536637e-05, 9.99985832e-01],\n",
       "        [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 2.41540059e-05, 9.99999999e-01]]),\n",
       " 'Breed1': array([307, 307, 266, ..., 218, 307, 266]),\n",
       " 'Breed2': array([  0, 179,   0, ..., 307,   0,   0])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KUCIqcb8jOww",
    "outputId": "ac025bfe-6870-4a80-bc68-994bf1cbd111"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_features_input_shape = (X_train['direct_features'].shape[1],)\n",
    "direct_features_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEm6aCZtjOw6"
   },
   "source": [
    "## Creando datasets iterables\n",
    "\n",
    "Como hemos visto, las redes neuronales se entrenan iterativamente con el algoritmo de *stochastic gradient descent*. Una forma de hacerlo es pasarle el dataset entero al método `fit` de un modelo de Keras, como vimos en la notebook anterior. Sin embargo, esto tiene algunas desventajas:\n",
    "\n",
    "* El dataset procesado debe entrar en memoria\n",
    "* El dataset procesado debe entrar en disco, lo cual no siempre es factible para encodings y datasets realmente grandes (ej: la wikipedia)\n",
    "* Una vez que la GPU ha terminado de procesar los datos, devuelve el control a la CPU (que estaba esperando sin hacer nada), y espera a que los nuevos datos son particionados.\n",
    "* No es posible usar cálculo distribuido en distintos file systems.\n",
    "\n",
    "Las dos primeras desventajas se solucionan preprocesando los datos en batches, y creando matrices anchas pero con pocas filas. Sin embargo, escribir este código manualmente puede ser complejo y en general lo hacemos de manera ineficiente. Solucionar las dos últimas es bastante más complicado y a la vez crítico. \n",
    "\n",
    "> **No importa qué tan buen hardware usemos para el entrenamiento del modelo, si seguimos limitados por un procesamiento de datos lineal y single core.**\n",
    "\n",
    "Por eso es recomendable utilizar las abstracciones nativas provistas por Tensorflow que paralelizan internamente muchas funciones.\n",
    "\n",
    "Para ello, crearemos un objeto `tf.data.Dataset` iterable a partir de nuestro dataframe de pandas y no tendremos que preocuparnos por la optimización de la GPU. Los datasets saben cómo crear batches, shuffles, aplicar funciones map y filter, etc. Además, podemos crear datasets a partir de diversas estructuras de datos, como numpy arrays o archivos. Pueden encontrar más información sobre los distintos tipos de Datasets en [este tutorial](https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPB_yRzMjOw8"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "shuffle_size = 100\n",
    "# TODO shuffle the train dataset!\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.shuffle(shuffle_size)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    process_features(dev_dataset)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYWJMfiBjOxG"
   },
   "source": [
    "Podemos ver qué es lo que tiene adentro en dataset obteniendo la primera operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "pSiOKw1HjOxI",
    "outputId": "3ac40639-086b-4632-ad5c-817f45f8105f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'direct_features': <tf.Tensor: id=37853, shape=(32, 49), dtype=float64, numpy=\n",
       "  array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.41978415e-05, 9.99999999e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "          0.00000000e+00, 9.67702910e-05, 9.99999994e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.83080109e-05, 9.99999980e-01],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.41978415e-05, 9.99999997e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "          1.20980333e-02, 4.83921331e-05, 9.99926646e-01],\n",
       "         [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.41540058e-05, 9.99999995e-01]])>,\n",
       "  'Breed1': <tf.Tensor: id=37851, shape=(32,), dtype=int64, numpy=\n",
       "  array([266, 307, 266, 179, 265, 266, 109, 307, 179, 307, 276, 266, 307,\n",
       "         266, 169, 265, 207, 307, 307, 266, 307, 195,  78, 307, 266, 299,\n",
       "         307, 285, 307, 307,  76, 265])>,\n",
       "  'Breed2': <tf.Tensor: id=37852, shape=(32,), dtype=int64, numpy=\n",
       "  array([  0,   0,   0,   0,   0,   0, 307,   0,   0,   0, 292,   0,   0,\n",
       "           0, 307,   0,   0,   0,   0, 266,   0, 179, 307,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0])>},\n",
       " <tf.Tensor: id=37854, shape=(32, 5), dtype=float32, numpy=\n",
       " array([[0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(train_ds))\n",
    "x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IqpWCCD_jOxQ"
   },
   "source": [
    "## Construyendo el modelo\n",
    "\n",
    "Construimos el modelo, por ahora con sólo una capa oculta. Sin embargo, la complejidad más grande es combinar los features que tienen embeddings con los que no. Por cada tipo de feature, tenemos que agregar una capa de `Input`. Tener en cuenta que cada embedded feature se considera distinto.\n",
    "\n",
    "Como tenemos más de un input, tenemos que usar la API funcional de Keras en lugar de usar un modelo `Sequential`. La API funcional puede construir modelos más flexibles, ya que conectaremos explícitamente cada capa con su capa siguiente.\n",
    "\n",
    "Pueden encontrar otro ejemplo similar a este código en [esta notebook](https://www.kaggle.com/alexanderkireev/deep-learning-support-9663)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "W0q0yPNujOxV",
    "outputId": "6e14ac95-4360-4e52-ca74-3683d5fd153d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding embedding of size 77 for layer Breed1\n",
      "Adding embedding of size 77 for layer Breed2\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "hidden_layer_size = 64\n",
    "\n",
    "# Add one input and one embedding for each embedded column\n",
    "embedding_layers = []\n",
    "inputs = []\n",
    "for embedded_col, max_value in embedded_columns.items():\n",
    "    input_layer = layers.Input(shape=(1,), name=embedded_col)\n",
    "    inputs.append(input_layer)\n",
    "    # Define the embedding layer\n",
    "    embedding_size = int(max_value / 4)\n",
    "    embedding_layers.append(\n",
    "        tf.squeeze(layers.Embedding(input_dim=max_value, output_dim=embedding_size)(input_layer), axis=-2))\n",
    "    print('Adding embedding of size {} for layer {}'.format(embedding_size, embedded_col))\n",
    "\n",
    "# Add the direct features already calculated\n",
    "direct_features_input = layers.Input(shape=direct_features_input_shape, name='direct_features')\n",
    "inputs.append(direct_features_input)\n",
    "    \n",
    "# Concatenate everything together\n",
    "features = layers.concatenate(embedding_layers + [direct_features_input])\n",
    "dropout1 = layers.Dropout(0.25)(features)\n",
    "flatten = layers.Flatten()(dropout1)\n",
    "dense1 = layers.Dense(hidden_layer_size, activation='relu')(flatten)\n",
    "dropout2 = layers.Dropout(0.5)(dense1)\n",
    "output_layer = layers.Dense(nlabels, activation='softmax')(dropout2)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_BEeCOhNjOxd"
   },
   "source": [
    "### Métricas de evaluación\n",
    "\n",
    "Al igual que en la materia de aprendizaje supervisado, utilizaremos el accuracy como métrica, y agregaremos el score f1. Es opcional implementar esta predicción como un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "pIXDl0_mjOxf",
    "outputId": "35008717-316b-454c-9802-d268b1338edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Breed2 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 77)        23716       Breed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_1 (TensorFl [(None, 77)]         0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "direct_features (InputLayer)    [(None, 49)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 203)          0           tf_op_layer_Squeeze[0][0]        \n",
      "                                                                 tf_op_layer_Squeeze_1[0][0]      \n",
      "                                                                 direct_features[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 203)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 203)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           13056       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            325         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 60,813\n",
      "Trainable params: 60,813\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9owIc28jOxp"
   },
   "source": [
    "## Entrenando el modelo\n",
    "\n",
    "Una vez que tenemos definido nuestro modelo, tenemos que entrenarlo. Sin embargo, para que los resultados sean útiles, tenemos que llevar un registro de qué hiperparámetros utilizamos y qué performance obtuvimos. Para eso, usaremos [MLFlow](https://mlflow.org/docs/latest/quickstart.html), una librería muy simple pero que permite sistematizar el registro de resultados.\n",
    "\n",
    "MLFlow soporta muchísimos casos de uso, pero por ahora sólo usaremos el más básico de todos para organizar el entrenamiento. Llamaremos *experiments* a los cambios grandes en la arquitectura, por ejemplo, si agregamos muchas capas nuevas o mecanismos de regularización. Llamaremos *runs* a las distintas ejecuciones de la misma arquitectura donde variamos sólo algunos hiperparámetros, como funciones de activación, cantidad de neuronas, tamaños de los embeddings, etc.\n",
    "\n",
    "Para acceder a la interfaz gráfica donde podemos ver las *run*, en una nueva terminal tenemos que ejecutar \n",
    "\n",
    "    $ mlflow ui -p PORT\n",
    "    \n",
    "Y abrir `https://localhost:PORT` en nuestro navegador (donde `PORT` es un número de puerto). Si estamos en un servidor, es probab, tendremos que abrir un nuevo puerto ssh a `PORT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "920ZwWtEjOxt",
    "outputId": "ccca9404-f8af-469b-dfb0-ce89499bf6d9"
   },
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVmwY3CejOxz",
    "outputId": "e1af7641-139b-40ed-e6d0-c5a0860ccbc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "265/265 [==============================] - 4s 14ms/step - loss: 1.4962 - accuracy: 0.2849\n",
      "Epoch 2/10\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 1.4381 - accuracy: 0.3269\n",
      "Epoch 3/10\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 1.4306 - accuracy: 0.3396\n",
      "Epoch 4/10\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 1.4169 - accuracy: 0.3464\n",
      "Epoch 5/10\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 1.4115 - accuracy: 0.3549\n",
      "Epoch 6/10\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 1.4047 - accuracy: 0.3549\n",
      "Epoch 7/10\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 1.4003 - accuracy: 0.3626\n",
      "Epoch 8/10\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 1.3946 - accuracy: 0.3712\n",
      "Epoch 9/10\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 1.3861 - accuracy: 0.3733\n",
      "Epoch 10/10\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 1.3813 - accuracy: 0.3713\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 1.4246 - accuracy: 0.3472\n",
      "*** Test loss: 1.4245565417987198 - accuracy: 0.34718942642211914\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment('very_base_approach')\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    # Log model hiperparameters first\n",
    "    mlflow.log_param('hidden_layer_size', hidden_layer_size)\n",
    "    mlflow.log_param('embedded_columns', embedded_columns)\n",
    "    mlflow.log_param('one_hot_columns', one_hot_columns)\n",
    "    mlflow.log_param('numerical_columns', numeric_columns)  # Not using these yet\n",
    "    \n",
    "    # Train\n",
    "    epochs = 10\n",
    "    history = model.fit(train_ds, epochs=epochs)\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, accuracy = model.evaluate(test_ds)\n",
    "    print(\"*** Test loss: {} - accuracy: {}\".format(loss, accuracy))\n",
    "    mlflow.log_metric('epochs', epochs)\n",
    "    mlflow.log_metric('loss', loss)\n",
    "    mlflow.log_metric('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kJAb8M6jOx-"
   },
   "source": [
    "## Evaluando del modelo\n",
    "\n",
    "Además de tener en cuenta las métricas de performance del modelo, es importante mirar los resultados obtenidos y controlar que el modelo efectivamente está aprendiendo algo relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUhll7QLjOyC",
    "outputId": "c25e1903-393c-407f-efb2-0538bb488c7e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f09e00cda10>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = numpy.argmax(model.predict(test_ds), axis=1)\n",
    "seaborn.countplot(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando submission ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features_sub(df):\n",
    "    direct_features = []\n",
    "\n",
    "    # Create one hot encodings\n",
    "    for one_hot_col, max_value in one_hot_columns.items():\n",
    "        direct_features.append(tf.keras.utils.to_categorical(df[one_hot_col] - 1, max_value))\n",
    "\n",
    "    direct_features.append(tf.keras.utils.normalize(df[numeric_columns],1))   \n",
    "    \n",
    "    \n",
    "    # Concatenate all features that don't need further embedding into a single matrix.\n",
    "    features = {'direct_features': numpy.hstack(direct_features)}\n",
    "\n",
    "    # Create embedding columns - nothing to do here. We will use the zero embedding for OOV\n",
    "    for embedded_col in embedded_columns.keys():\n",
    "        features[embedded_col] = df[embedded_col].values\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>Description</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>Siu Pak just give birth on 13/6/10 to 6puppies...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>Very manja and gentle stray cat found, we woul...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>41326</td>\n",
       "      <td>Kali is a super playful kitten who is on the g...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "0     2    1     265       0       1       1       2       0             2   \n",
       "1     1    1     307       0       1       2       7       0             2   \n",
       "2     1    0     307       0       2       1       2       7             2   \n",
       "3     2   12     265       0       2       1       7       0             2   \n",
       "4     2    3     264       0       2       1       2       5             3   \n",
       "\n",
       "   FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  State  \\\n",
       "0          2           3         3           3       1         1    0  41401   \n",
       "1          2           1         1           2       1         1    0  41326   \n",
       "2          1           2         2           2       1         6    0  41326   \n",
       "3          2           3         3           3       1         1    0  41326   \n",
       "4          3           1         1           2       1         1   50  41326   \n",
       "\n",
       "                                         Description  PID  \n",
       "0  I just found it alone yesterday near my apartm...    1  \n",
       "1  Their pregnant mother was dumped by her irresp...    2  \n",
       "2  Siu Pak just give birth on 13/6/10 to 6puppies...    7  \n",
       "3  Very manja and gentle stray cat found, we woul...    9  \n",
       "4  Kali is a super playful kitten who is on the g...   11  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val = pandas.read_csv(os.path.join(DATA_DIRECTORY, 'test.csv'))\n",
    "dataset_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = process_features_sub(dataset_val)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(val_x).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 2, ..., 1, 4, 1])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = numpy.argmax(model.predict(val_ds), axis=1)\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4406</td>\n",
       "      <td>14984</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4407</td>\n",
       "      <td>14986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4408</td>\n",
       "      <td>14987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4409</td>\n",
       "      <td>14989</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>14990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PID  AdoptionSpeed\n",
       "0         1              4\n",
       "1         2              2\n",
       "2         7              2\n",
       "3         9              4\n",
       "4        11              1\n",
       "...     ...            ...\n",
       "4406  14984              4\n",
       "4407  14986              2\n",
       "4408  14987              1\n",
       "4409  14989              4\n",
       "4410  14990              1\n",
       "\n",
       "[4411 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pandas.DataFrame(list(zip(dataset_val.PID, pred_val)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submission_dropout_flat_drop.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "2_data_processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
