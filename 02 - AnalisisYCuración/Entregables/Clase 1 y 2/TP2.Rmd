---
title: "R Notebook"
output: html_notebook
---

***
## Practico 2: Entregar un Rmd donde se:

- Elija un dataset clasificado de su preferencia y area (domain expertise), aplique un metodo de clustering y/o mixtura de Gaussianas en el mismo.

- Investigue los resultados en el meta parametro $K$ numero de cumulos e investigue posibles procesos de seleccion del mismo.

- Elabore un resumen, y selecione un mejor valor segun el/los criterios aplicados, discuta el significado de los cumulos
encontrados. 

- Comente la influencia de la normalizacion de los datos en los resultados del clustering.




```{r echo=TRUE}

df <- read.csv("df_prop_clean.csv")
print(df)
```



```{r echo=TRUE}
df_prop_type <- df[,c(14)]

df_train <- df[1:5000,-14] 
df_test <- df[5001:7716,-14]

```

```{r echo=TRUE}
df_train
str(df_train)
```

```{r echo=TRUE}
pca.train <- df_train
pca.test <- df_test
```

```{r echo=TRUE}
#principal component analysis
prin_comp <- prcomp(pca.train, scale. = TRUE)
print(prin_comp)
```


```{r echo=FALSE}
# plot method
plot(pca.train, type = "l")
```

```{r echo=TRUE}
# summary method
summary(pca.train)


```

```{r echo=TRUE}
# summary method
plot(pca.train$x[,1:2], col= df_prop_type)

```


C:\Users\Agustina-Notebook\Documents\DiploDatos\Repopracticos\DiploDatos\02 - AnalisisYCuraciÃ³n\Entregables\Clase 1 y 2\datasets

NO SUPERVISADO
TP2_BlackFriday.csv

SUPERVISADO
TP2_Google-Playstore-32K.csv

```{r echo=TRUE}
data <- read.csv("df_prop_clean.csv")
print(data)
```



***
### Entendiendo los datos:
Independientemente del metodo de ML aplicado, las variables de identificacion **deben** ser excluidas. No hacerlo puede llevar a hallazgos erroneos a causa de que la identificacion puede ser utilizada para predecir muy bien.
La siguiente variable, el diagnostico es de particular interes, por que es lo que se quiere predecir.


```{r echo=TRUE}
table(data$V32)
```

Ya que estamos miremos el resto de las variables, sus rangos etc.

```{r echo=TRUE}
summary(data)
```

***
### Transformacion de los datos:

Necesitamos crear una funcion normalizacion en R:

```{r echo=TRUE}
normalize <- function(x) {
  return ((x-min(x))/(max(x)-min(x)))
}
```

Despues de ejecutar el codigo previo, la funcion esta disponible para sus uso. Veamos si funciona en algunos vectores.

```{r echo=TRUE}
normalize(c(1,2,3,4,5))
normalize(c(10,20,30,40,50))
```

No podemos aplicar la funcion a los features numericos del dataframe directamente.

***
### Transformacion de los datos:

La funcion lapply() de R toma una lista y aplica una funcion a cada elemento de la lista.


```{r echo=TRUE}
data_n <- as.data.frame(lapply(data[1:31], normalize))
summary(data_n$V3)
summary(data_n$V8)
```

Bingo!  En ausencia de nuevos datos de laboratorio, vamos a simular este escenario dividiendo 
nuestros datos en una **muestra de entrenamiento**  que usaremos para construir el modelo kNN 
y una **muestra de validacion** que usaremos para medir la precision predictiva del mismo.

***
### Entrenando un clasificador:

Notese que dichos conjuntos de datos deben ser representativos del conjunto de datos, i.e. **metodos de muestreo aleatorios**!

```{r echo=TRUE}
data_train <- data_n[1:5000, ]
data_test  <- data_n[5001:7616, ] 
```

Excluimos la variable objetivo (Benigno/Maligno), pero necesitamos guardar estos factores en vectores!

```{r echo=TRUE}
data_train_labels <- data[1:5000, 1]
data_test_labels  <- data[5001:7616, 1]
```


Para el algoritmo kNN la fase de entrenamiento no involucra construir un modelo, para
clasificar nuestros datos de validacion utilizaremos el paquete class, instalarlo ia!

La datos de validacion son clasificados tomando los votos entre los k vecinos mas cercanos
del conjunto de entrenamiento. Si hay empate se decide aleatoriamente. Entonces usamos
la funcion knn() para clasificar.

***
### Evaluando la performance del modelo.


```{r echo=TRUE}
library(class)
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=21)
```

El siguiente paso en el proceso es evaluar como las clases predichas  en data_test_pred
se condicen con los valores verdaderos en el vector data_test_labels.

```{r echo=TRUE}
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE)
```

